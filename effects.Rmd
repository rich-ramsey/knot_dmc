---
title: "plot"
author: "Rich"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file tries to make a quick summary plot for the knot dmc project.

I made a plot like this recently to summarise Raph's results. 

Eventually, we could add the rt dist for acc/inc in the raw data below, as we did for Raph's data.


# load the libraries that we will be using #

## load packages ##

```{r load-pkg}
source ("dmc/dmc.R")

pkg <- c("tidyverse", "RColorBrewer", "patchwork", "tidybayes")

lapply(pkg, library, character.only = TRUE)
```

## plot settings ##

theme settings for ggplot

```{r, eval = F}
theme_set(
  theme_bw() +
    theme(text = element_text(size = 18, face="bold"), 
          title = element_text(size = 18, face="bold"),
          legend.position = "bottom")
)

## Set the amount of dodge in figures
pd <- position_dodge(0.7)
pd2 <- position_dodge(1)
```

## load the model object and/or data ##

```{r}
## The model object is available upon request
## Please email Samantha Parker (samantha.parker@students.mq.edu.au) or Richard Ramsey (richard.ramsey@hest.ethz.ch)
## load("models/modelKN.RData") ##  
load_model ("LBA","lba_B.R")
```

# section 1 - posterior predictions #

Posterior predictions take the model and make predictions in original units (i.e., accuracy and rt).
This is always useful as a model checking process - does the model generate sensible data?

## create a ggplot ready (i.e., tidy) list of dfs at the group level ##

```{r}
## posterior predictions with gglist=TRUE
ppKNgg <- h.post.predict.dmc(hKN, cores=8, gglist = TRUE)
group_ppX <- attr(attr(ppKNgg, "av"), "gglist")
head(group_ppX)
str(group_ppX)
```

## take out relevant dfs for plotting ##

```{r}
# pps - posterior predictive
pps <- group_ppX %>% 
  pluck("pps")
head(pps)
str(pps)

# data 
# not necessary, but keeps it "tidy" i.e., one datapoint / observation per row
d <- pps %>% 
  select(S, GRP, R, data)
head(d)
str(d)

# rt quantiles
rt_q <- group_ppX %>% 
  pluck("RTs")
head(rt_q)
str(rt_q)
```

## plot accuracy ##

- dot for data
- dot and error bar for post preds

```{r}
p1.1 <- ggplot(pps, aes(x=R, y=median, 
                           fill=R, colour=R)) +
   geom_jitter(data = d,
               aes(y=data),
               position=position_jitterdodge(),
               alpha = 1, colour = "darkgrey", size = 3) +
   geom_point(alpha = 3, position = pd2, size = 3) +
   geom_line(aes(group = 1), position = pd2, colour = "black") +
   geom_errorbar(aes(ymin = lower, ymax = upper),
                width=.2, position=pd2) +
   scale_fill_brewer(palette = "Dark2") +
   scale_colour_brewer(palette = "Dark2") +
   ggtitle("accuracy") +
   labs(y="accuracy (%)") + 
   facet_grid(GRP~S)
p1.1
```

## plot the the RT quantiles ##

```{r}
p1.2 <- ggplot(rt_q, aes(x=R, y=median, colour=R)) +
   geom_point(aes(y=data),
              # position = pd2,
              alpha = 1, colour = "darkgrey", size = 3) +
   geom_point(alpha = 3, size = 3) +
   geom_line(aes(group = quantile), colour = "black") +
   geom_errorbar(aes(ymin = lower, ymax = upper),
                width=.2) +
   scale_fill_brewer(palette = "Dark2") +
   scale_colour_brewer(palette = "Dark2") +
   ggtitle("RT quantiles") +
   labs(y="reaction time (s)") + 
   facet_grid(GRP~S)
p1.2
```

## plot them together using patchwork ##

```{r}
p1.3 <- p1.1 | p1.2
p1.3

## you could save a figure at this point, if you wanted
ggsave("figures/ppreds.jpeg",
       width = 10, height = 8)
```


# section 2 #

## what about visualising parameters from the model? ##

As well as the posterior predictions, we also want to plot and summarise the estimated parameters from the posterior distribution. e.g., drift rate, response caution etc. So let's take a look at that.

Note to Raph/Sam and a reminder for Rich: One thing that took a little (or rather a lot of) figuring out was how the DMC compare.p convenience function calculates group average parameter estimates for the posterior distribution. It takes all pid posteriors, averages them first and then calculates the relevant quantiles to display and make inferences from. In other words, it first summarises parameters over pid 1, 2, 3, etc. and then calculates quantiles. This matters, because you could also calculate the quantiles without first averaging. So, the below has been tested to produce the same outputs as the compare.p function, which is re-assuring.

But instead of using compare.p, we take the posterior distributions from the samples object and then summarise and plot the results ourselves.

## wrangle all parameters and take a quick look ##

This is just to get a quick overview of all 9 parameters (before we perform any contrasts/comparisons between conditions).

## wrangle the samples first into a tidy format ##

transpose samples and pluck theta out into a list of arrays

```{r}
array_theta <- hKN %>%
  transpose() %>% 
  pluck("theta")
summary(array_theta)
str(array_theta)
```

make it tidy

```{r}
## and now use the slightly longer way with map and tidyr
theta_pid <-  map(array_theta,~as_tibble(., rownames = "chain")) %>% 
  list_rbind(names_to = "pid") %>%
  rename_with(~str_replace_all(.x, '\\.', '_')) %>% ## replace periods with underscores in names, as things work better below without periods in names
  pivot_longer(-c(pid, chain),
               values_to = "value",
               names_to = c("param", "iter"), ## this is the order of the array
               names_pattern = "([A-Za-z_\\d?]+)_(\\d+)") %>%  ## letters, _, optional digit before the underscore separator. digits after the underscore separator
  select(pid, iter, chain, param, value) %>% ## reorder columns
  arrange(pid, iter, chain, param) %>% 
  mutate(param=factor(param),
         pid=factor(pid)) %>% ## create factors
  mutate_if(is.character, as.integer) ## change from characters to integers
summary(theta_pid)
str(theta_pid)
head(theta_pid)

## data check for param
data.check <- theta_pid %>% 
  distinct(param) %>% 
  print(n=Inf)

## ok, the df has 6,534,000 rows.
## this makes sense to me. 18 pid x 250 iter x 66 chains * 22 params = 6534000
## 18*250*66*22
## =6534000
```

## create a group summary distribution ##

summarise across pid (to be consistent with the DMC compare.p function)

```{r}
theta_group <- theta_pid %>%
  group_by(iter, chain, param) %>% 
  summarise(value = mean(value)) %>% 
  ungroup() %>% 
  add_column(pid = "average") %>% ## add a column which makes clear it is the avg. not needed but useful for plotting later
  relocate(pid, .before = everything())
head(theta_group)
glimpse(theta_group)

## 6534000/18pid = 363,000 rows
```

## calculate quantiles ##

calculate quantiles per parameter at the group level

```{r}
theta_group_q <- theta_group %>%
  group_by(param) %>% 
  median_qi(value)
theta_group_q
```

and do the same per pid

```{r}
theta_pid_q <- theta_pid %>%
  group_by(pid, param) %>% 
  median_qi(value)
theta_pid_q
```

## some quick and dirty plots with all of the parameters ##

plot the distribution per parameter using a tidybayes halfeye plot

```{r}
p2.1 <- ggplot(theta_group, aes(x = value, y = fct_rev(param))) +  
  stat_halfeye(alpha = 0.9) +
  labs(x = "parameter estimate", y = "") 
p2.1

ggsave("figures/all_params.jpeg",
       width = 8, height = 6)
```

plot avg and individual pid parameters

```{r}
p2.2 <- ggplot(theta_group, aes(x = value, y = fct_rev(param))) +  
  stat_halfeye(alpha = 0.9, position = position_nudge(y=-0.5)) +
  geom_pointinterval(data = theta_pid_q, aes(xmin=.lower, xmax=.upper, 
                                           colour = pid, fill = pid),
                     position = position_dodge(width = 0.7)) +
  labs(x = "parameter estimate", y = "") +
  facet_wrap(~param, scales = "free_y") +
  theme(legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
p2.2

ggsave("figures/all_params_pid.jpeg",
       width = 10, height = 10)
```


Ok, at this point, we could wrangle the data and make some nice plots.
For code on how to do this, see folder /pilot5_dmc/ in Raph's project.
But Sam has already done that using the compare.p function and so there is no real need to reproduce those.
Instead, we should try to move on to visualise the average parameter estimates from the model in a LBA model type way.  
For that, we only need the average estimates per parameter, which we calculated above already.

# Section 3 - make a plot to visualise the results in LBA model format? ##

Can I produce a plot with RT and acc alongside model terms in a classic LBA model
visualisation?

e.g., take the raw data and make density dists, then plot alongside the parameters but in model format, rather than posterior distributions?

Let's have a play around and see.

For ease, we will just take a median value per parameter and plot to illustrate the main message.This might be justifiable, as the posterior distribution contains the uncertainty and interval estimates and we make our conclusions based on those.

This plot could just characterise/visualise the main results in a LBA schematic kind
of way. 
And that way may be more intuitive and provide an overview for readers of the main findings.


## wrangle threshold and drift rate ##

maybe just plot the average for now.

let's first take some key values of interest from the parameter medians and then combine them into one df

```{r}
## select medians of interest
theta_group_qf <- theta_group_q %>% 
  select(param, value) %>% 
  filter(!param %in% (c("sd_v_true")))
theta_group_qf

## create start point df
a_q <- theta_group_qf %>% 
  filter(param == "A") %>% 
  rename(start_point = value) %>% 
  select(-param)
a_q

## create threshold df
b_q <- theta_group_qf %>% 
  filter(str_detect(param, "^B_")) %>%
  mutate(condition = if_else(str_detect(param, "both"), "both",
                     if_else(str_detect(param, "name"), "name",
                     if_else(str_detect(param, "tie"), "tie", "untrained"))),       
         condition = factor(condition,
                            levels = c("untrained", "name", "tie", "both")),
         response = if_else(str_detect(param, "same"), "same", "diff"),
         response = factor(response,
                            levels = c("same", "diff"))) %>% 
  rename(threshold = value) %>% 
  select(condition, response, threshold)
b_q

## create drift rate df
v_q <- theta_group_qf %>% 
  filter(str_detect(param, "^mean_v")) %>% 
  mutate(condition = if_else(str_detect(param, "both"), "both",
                     if_else(str_detect(param, "name"), "name",
                     if_else(str_detect(param, "tie"), "tie", "untrained"))),       
         condition = factor(condition,
                            levels = c("untrained", "name", "tie", "both")),
         accuracy = if_else(str_detect(param, "true"), "true", "false"),
         accuracy = factor(accuracy,
                            levels = c("true", "false"))) %>% 
  rename(drift_rate = value) %>% 
  select(condition, accuracy, drift_rate)
v_q

## create a ndt df
t0_q <- theta_group_qf %>%
  filter(str_detect(param, "^t0")) %>% 
  mutate(condition = if_else(str_detect(param, "both"), "both",
                     if_else(str_detect(param, "name"), "name",
                     if_else(str_detect(param, "tie"), "tie", "untrained"))),       
         condition = factor(condition,
                            levels = c("untrained", "name", "tie", "both"))) %>%
  rename(ndt = value) %>% 
  select(condition, ndt)
t0_q
```

now create a plotting df and calculate some new variables

```{r}
theta_group_plot <- b_q %>% 
  inner_join(t0_q, by = "condition") %>% 
  inner_join(v_q, by = "condition",
             relationship = "many-to-many") %>% 
  mutate(start_point = a_q$start_point,
         b = start_point + threshold,
         xend = threshold / drift_rate) %>%
  select(condition, response, accuracy, start_point, ndt, drift_rate, threshold, 
         b, xend)
theta_group_plot

## notes on the calculations here:
## b = start point plus threshold as the threshold is the gap between where a trial starts until it reaches the threshold
## xend is required when using geom_segment (instead of geom_abline) and in this case it refers to the point on the x axis that corresponds to the threshold line
```

## plot the average ##

try geom_segment instead to restrict the plot to the threshold limit

```{r}
## if you want text labels, then this is one way to go...
labels <- tibble(x = c(1.1, 1.5, 2,
                       1.1, 1.5, 1.7,
                       1.1, 1.5, 1.7,
                       1.1, 1.5, 2.5),
                 y = c(2.5, 4.6, 3.6,
                       2.5, 3.5, 2.9,
                       2.5, 3.5, 2.9,
                       2.5, 3.4, 2.9),
                 condition = rep(c("untrained", "name",
                                   "tie", "both"), each = 3),
                 label = rep(c("start point (A)",
                               "threshold (b)", "drift rate (v)"), times = 4)) %>%
                 mutate(condition = factor(condition,
                                           levels = c("untrained", "name",
                                                      "tie", "both")))
labels

## define rectangle for ndt
rect <- tibble(condition = c("untrained", "name", "tie", "both")) %>%
  mutate(condition = factor(condition, 
                            levels = c("untrained", "name", "tie", "both")),
         ndt = c(0.258/2, 0.501/2, 0.509/2, 0.524/2))
rect
  
## plot          
p2.1 <- ggplot(theta_group_plot) +
  geom_hline(aes(yintercept = b, linetype=response), 
             linewidth = 1, linetype = "longdash") +
  scale_y_continuous(limits = c(2,5), breaks = seq(2,5,1)) +
  scale_x_continuous(limits = c(0,3.2), breaks = seq(0,3.2,0.5)) +
  geom_segment(aes(x = ndt/2, y = start_point, 
                   xend = (ndt/2)+xend, yend = b,
                   colour = accuracy, linetype = accuracy), linewidth=1) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position = "none",
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.minor = element_blank()
        ) +
  xlab("accumulation time") +
  ylab("a.u.") +
  geom_rect(data = rect, aes(xmin = 0, xmax = ndt, ymin = -Inf, ymax = Inf), 
            alpha = 0.5, fill="darkgrey") +
  facet_wrap(~condition, nrow = 1) +
  geom_text(data = labels,
            aes(x=x,y=y, label = label),
            fontface = "bold")
p2.1

ggsave("figures/lba_summary.jpeg",
       width = 8, height = 5, dpi=800)
```

How about we try to add rt and acc desnity plots like we did before with Raph's data?

# Section 4 #

## read in the raw data and create density plots ##

```{r}
## extract data from the model object
array_data <- hKN %>%
  transpose() %>% 
  pluck("data")
summary(array_data)
str(array_data)

## make it tidy
data <-  map(array_data,~as_tibble(., rownames = "row")) %>% 
  list_rbind(names_to = "pid")
head(data)
summary(data)

## check it
data %>% 
  distinct(pid)
```

data check

```{r}
data %>% 
  distinct(S, GRP, R) %>% 
  arrange(S, GRP, R)

data %>%
  group_by(S, GRP, R) %>% 
  tally()
```

add an accuracy column

```{r}
data <- data %>%
  rename(rt=RT) %>% 
  mutate(response = R,
         accuracy = if_else(S == "match" & R == "same", "true",
                    if_else(S == "mis" & R == "diff", "true", "false")),       
         response = factor(response,
                          levels=c("same", "diff")),
         accuracy = factor(accuracy,
                           levels=c("true", "false")),
         condition = if_else(str_detect(GRP, "both"), "both",
                     if_else(str_detect(GRP, "name"), "name",
                     if_else(str_detect(GRP, "tie"), "tie", "untrained"))),
         condition = factor(condition,
                            levels = c("untrained", "name", "tie", "both")))
head(data)
```

check

```{r}
data %>% 
  distinct(S, GRP, R, response, accuracy, condition) 
```

## create summary data ##

## summary data ##

at the pid level

```{r}
acc_summary_pid <- data %>% 
  group_by(pid, response, condition) %>%
  summarise(sum = sum(as.numeric(accuracy)),
            n=n(),
            frac = n/sum,
            perc = frac*100,
            .groups = "drop")
acc_summary_pid
```

```{r}
rt_summary_pid <- data %>% 
  group_by(pid, response, condition, accuracy) %>%
  summarise(mean = mean(rt, na.rm = TRUE),
            n=n(),
            sd = sd(rt, na.rm = TRUE),
            sem=sd/sqrt(n),
            .groups = "drop")
rt_summary_pid
```

at the group level

```{r}
acc_summary <- data %>% 
  group_by(response, condition) %>%
  summarise(sum = sum(as.numeric(accuracy)),
            n=n(),
            frac = n/sum,
            perc = frac*100,
            .groups = "drop")
acc_summary
```

```{r}
rt_summary <- data %>% 
  group_by(response, condition, accuracy) %>%
  summarise(mean = mean(rt, na.rm = TRUE),
            n=n(),
            sd = sd(rt, na.rm = TRUE),
            sem=sd/sqrt(n),
            .groups = "drop")
rt_summary
```

join the data (not sure this is necessary, but it helps with plotting text
for the accuracy summary)

```{r}
# data <- data.model.v4 %>%
#   inner_join(select(acc_summary, condition, perc), by = "condition") 
# head(data.model.v4)
```

## some density plots ##

```{r}
p4.1 <- ggplot(data, aes(x=rt, y=after_stat(count))) +
  geom_density(aes(colour = accuracy, fill = accuracy),
               alpha = 0.5, position = "identity") +
  # xlim(0,2.5) +
  scale_x_continuous(limits = c(0,2.5), breaks = c(0,2,1)) +
  geom_vline(data = rt_summary, aes(xintercept = mean, colour = accuracy),
             linetype = "dashed", linewidth = 1) +
  geom_text(data = acc_summary, aes(x=2, y=300,
                                    label = sprintf("%.f%s", perc, "% accuracy")),
            color = "darkgrey", size = 5, fontface="bold") +
  scale_fill_brewer(palette = "Dark2") +
  scale_colour_brewer(palette = "Dark2") +
  facet_grid(response~condition) 
p4.1

ggsave("figures/density_rt_acc.jpeg",
       width = 12, height = 8, dpi=800)
```

## plot density and lba together? ##

```{r}
p4.2 <- (p2.1 / p4.1) +
  plot_layout(guides = "collect")
p4.2

ggsave("figures/lba_rt_acc.jpeg",
       width = 12, height = 10, dpi=800)
```