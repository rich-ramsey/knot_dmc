---
title: "model_rt_acc"
author: "Sam & Rich"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file builds Bayesian regression models using brms in order to analyses the manifest measures (accuracy and RT).

# load libraries #

```{r load-pkg}
pkg <- c("tidyverse", "RColorBrewer", "patchwork", "brms", "tidybayes", 
         "ggdist", "future", "bayesplot", "cmdstanr", "parallel", "rstan")

lapply(pkg, library, character.only = TRUE)
```

# plot settings #

theme settings for ggplot

```{r, eval = F}
theme_set(
  theme_bw() +
    theme(text = element_text(size = 18, face = "bold"), 
          title = element_text(size = 18, face = "bold"),
          legend.position = "bottom")
)

## Set the amount of dodge in figures
pd <- position_dodge(0.7)
pd2 <- position_dodge(1)
```

# package settings #

```{r}
options(brms.backend = "cmdstanr",
        mc.cores = parallel::detectCores(),
        future.fork.enable = TRUE,
        future.rng.onMisuse = "ignore") ## automatically set in RStudio

rstan_options(auto_write = TRUE)

supportsMulticore()

detectCores()
```

# 1. load the data #

accuracy data

```{r}
data_acc <- read_csv("data/processed/data_acc.csv") %>%
  mutate(PID = factor(PID),
         GROUP = factor(GROUP,
                        levels = c("untrained", "name", "tie", "both")))
head(data_acc)
glimpse(data_acc)
```

rt data

```{r}
data_rt <- read_csv("data/processed/data_rt.csv") %>%
  mutate(PID = factor(PID),
         GROUP = factor(GROUP,
                        levels = c("untrained", "name", "tie", "both")))
head(data_rt)
glimpse(data_rt)
```

# 2. load some models (as necessary) #

you will only need to load models if you've already created them and you want to take another look at them.

```{r}
# b0.1 <- readRDS("models/manifest/b0.1.rds")
# b0.2 <- readRDS("models/manifest/b0.2.rds")
# b0.3 <- readRDS("models/manifest/b0.3.rds")
# b1 <- readRDS("models/manifest/b1.rds")
# 
# ab0.1 <- readRDS("models/manifest/ab0.1.rds")
# ab0.2 <- readRDS("models/manifest/ab0.2.rds")
# ab1 <- readRDS("models/manifest/ab1.rds")
```

# 3. take a quick look at the lowest RT per person and on average across the group #

This is useful to get a feel for the ndt parameter

```{r}
pid_min <- data_rt %>% 
  group_by(PID) %>%
  summarise(min = min(RT), 
            avg = mean(RT))
pid_min

group_min <- pid_min %>% 
  summarise(min_avg = mean(min), 
            avg = mean(avg))
group_min
```

# 4. build some models #

## A note on priors for shifted log normal models ##

I think the ndt prior changes once it moves from a 'family specific parameter' to a population-level effect. In the former I think it is specified in different units to the latter - in the latter it is specified in log units. Short story is as follows: if you specify ndt in the wrong units, the model will scream and kick up a fuss. It matters if the prior is:

- class = 'ndt'
or
- class = 'Intercept', dpar = "ndt" (e.g., a distributional model, I think)

the latter prior is specified in log units (if I am following correctly).

Also, it seems sensible to keep the rt dv in ms. I think in log normal models, brms/stan freaks out when it is in seconds and log units because you get crazy negative initial starting numbers (inits) too easily and problems arise and no sampling is done.

## rt models ##

build some reaction time models first

### Model b0.1 - intercepts only model ###

formula

```{r}
formula = bf(RT ~ 1)
```

check the priors available

```{r}
get_prior(formula,
          data = data_rt, family = shifted_lognormal())
```

set priors

```{r}
priors = c(
  set_prior('normal(6.68, 0.5)', class = 'Intercept'),  # around 800ms
  set_prior('normal(5.99, 0.5)', class = 'ndt'),  # around 400ms
  # set_prior('normal(0, 0.5)', class = 'b'),
  # set_prior('normal(0, 0.5)', class = 'sd'), # variation across pID (in future models)
  # set_prior('normal(0, 0.5)', class = 'sd', dpar='ndt'),
  set_prior('normal(0, 0.5)', class = 'sigma') # SD of individual rts in
  # set_prior("lkj(2)", class = "cor") # correlation between varying effects log-units
)
```

build the model

```{r}
plan(multicore)
b0.1 <- brm(formula = formula,
        data = data_rt, family = shifted_lognormal(),
        prior = priors,
        iter = 2000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/b0.1")
summary(b0.1)
```

pp_checks

```{r}
ppb0.1 <- pp_check(b0.1, ndraws = 100)
ppb0.1

pmed0.1 <- pp_check(b0.1, type = "stat", stat = 'median', ndraws = 100)
pmed0.1
```

### Model b0.2 - intercepts only model with variation by pid ###

formula

```{r}
formula = bf(RT ~ 1 +
               (1 | PID))
```

check the priors available

```{r}
get_prior(formula,
          data = data_rt, family = shifted_lognormal())
```

set priors

```{r}
priors = c(
  set_prior('normal(6.68, 0.5)', class = 'Intercept'),  # around 800ms
  set_prior('normal(5.99, 0.5)', class = 'ndt'),  # around 400ms
  # set_prior('normal(0, 0.05)', class = 'b'),
  set_prior('normal(0, 0.5)', class = 'sd'), # variation across pID (in future models)
  # set_prior('normal(0, 0.5)', class = 'sd', dpar='ndt'),
  set_prior('normal(0, 0.5)', class = 'sigma') # SD of individual rts in
  # set_prior("lkj(2)", class = "cor") # correlation between varying effects log-units
)
```

build the model

```{r}
plan(multicore)
b0.2 <- brm(formula = formula,
        data = data_rt, family = shifted_lognormal(),
        prior = priors,
        iter = 4000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/b0.2")
summary(b0.2)
```

pp_checks

```{r}
ppb0.2 <- pp_check(b0.2, ndraws = 100)
ppb0.2

pmed0.2 <- pp_check(b0.2, type = "stat", stat = 'median', ndraws = 100)
pmed0.2
```

### Model b0.3 - b0.2 plus variation by pid in ndt ###

formula

```{r}
formula = bf(RT ~ 1 +
               (1 | PID),
               ndt ~ (1 | PID))
```

check the priors available

```{r}
get_prior(formula,
          data = data_rt, family = shifted_lognormal())
```

set priors

```{r}
priors = c(
  set_prior('normal(6.68, 0.5)', class = 'Intercept'),  # around 800ms
  set_prior('normal(5.99, 0.5)', class = 'Intercept', dpar = 'ndt'),  # around 400ms
  # set_prior('normal(0, 0.05)', class = 'b'),
  set_prior('normal(0, 0.5)', class = 'sd'), # variation across pID (in future models)
  set_prior('normal(0, 0.5)', class = 'sd', dpar='ndt'),
  set_prior('normal(0, 0.5)', class = 'sigma') # SD of individual rts in
  # set_prior("lkj(2)", class = "cor") # correlation between varying effects log-units
)
```

build the model

```{r}
plan(multicore)
b0.3 <- brm(formula = formula,
        data = data_rt, family = shifted_lognormal(),
        prior = priors,
        iter = 4000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/b0.3")
summary(b0.3)
```


pp_checks

```{r}
ppb0.3 <- pp_check(b0.3, ndraws = 100)
ppb0.3

pmed0.3 <- pp_check(b0.3, type = "stat", stat = 'median', ndraws = 100)
pmed0.3
```

### model b1 - add cue GROUP (training condition) as a predictor ###

Note - this includes GROUP (training condition) as a fixed / population effect, as well as a varying effect by pid.

formula

```{r}
formula = bf(RT ~ 1 + GROUP +
             (1 + GROUP | PID),
             ndt ~ (1 | PID))
```

check the priors available.

```{r}
get_prior(formula,
          data = data_rt, family = shifted_lognormal())
```

set priors 

```{r}
priors = c(
  set_prior('normal(6.68, 0.5)', class = 'Intercept'),  # around 800ms
  set_prior('normal(5.99, 0.5)', class = 'Intercept', dpar = "ndt"),  # around 500ms
  set_prior('normal(0, 0.5)', class = 'b'),
  set_prior('normal(0, 0.5)', class = 'sd'), # variation across pID 
  set_prior('normal(0, 0.5)', class = 'sd', dpar='ndt'),
  set_prior('normal(0, 0.5)', class = 'sigma'), # SD of individual rts in
  set_prior("lkj(2)", class = "cor") # correlation between varying effects log-units
)
```

build the model

```{r}
plan(multicore)
b1 <- brm(formula = formula,
        data = data_rt, family = shifted_lognormal(),
        prior = priors,
        iter = 6000, warmup = 2000, cores = 8, chains = 4,
        control = list(adapt_delta = 0.99, max_treedepth = 15),
        save_pars = save_pars(all=TRUE),
        seed = 123,
        init = 0.1,
        file = "models/manifest/b1")
summary(b1)
```

Plot

```{r}
# p1 = plot(conditional_effects(b1), plot=FALSE)
# 
# wrap_plots(p1)
```

pp_checks

```{r}
ppb1 <- pp_check(b1, ndraws = 100)
ppb1

pmedb1 <- pp_check(b1, type = "stat", stat = 'median', ndraws = 100)
pmedb1
```


## accuracy models ##

Ok, so my thinking is that accuracy should be modelled as a Bernoulli distribution. Bernoulli is a special case of the binomial when N=1 i.e., trials = 1. As these data are being modelled as trial-level data, then each trial is modelled as a Bernoulli. It is identical (I think) in brms to do a binomial with trials = 1. I guess this would be different if we were using aggregate data e.g., data aggregated over conditions, for example. In which case, N would be > 1 and the number correct could be a lot more than 0/1. 

prepend 'a' to model names to denote accuracy 

### model ab0.1 - intercepts only model ###

formula

```{r}
formula = bf(ACC ~ 1)
```

check the priors available

```{r}
get_prior(formula,
          data = data_acc, family = bernoulli(link = "logit"))
```

set priors

```{r}
priors = c(
  set_prior('normal(0, 1)', class = 'Intercept')  # 
)
```

build the model

```{r}
plan(multicore)
ab0.1 <- brm(formula = formula,
        data = data_acc, family = bernoulli(link = "logit"),
        prior = priors,
        iter = 4000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/ab0.1")
summary(ab0.1)
```

pp_checks

```{r}
ppab0.1 <- pp_check(ab0.1, ndraws = 100)
ppab0.1
```

### model ab0.2 - intercepts only model with variation by pid ###

formula

```{r}
formula = bf(ACC ~ 1 +
               (1 | PID))
```

check the priors available

```{r}
get_prior(formula,
          data = data_acc, family = bernoulli(link = "logit"))
```

set priors

```{r}
priors = c(
  set_prior('normal(0, 1)', class = 'Intercept'),
  set_prior('normal(0, 0.5)', class = 'sd')
)
```

build the model

```{r}
plan(multicore)
ab0.2 <- brm(formula = formula,
        data = data_acc, family = bernoulli(link = "logit"),
        prior = priors,
        iter = 4000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/ab0.2")
summary(ab0.2)
```

pp_checks

```{r}
ppab0.2 <- pp_check(ab0.2, ndraws = 100)
ppab0.2
```

### model ab1 - add GROUP (training condition) as a predictor ###

Note - this includes group (training type) as a fixed / population effect, as well as a varying effect by pid

formula

```{r}
formula = bf(ACC ~ 1 + GROUP +
             (1 + GROUP | PID))
```

check the priors available

```{r}
get_prior(formula,
          data = data_acc, family = bernoulli(link = "logit"))
```

set priors

```{r}
priors = c(
  set_prior('normal(0, 1)', class = 'Intercept'),
  set_prior('normal(0, 0.5)', class = 'sd'),
  set_prior('normal(0, 0.5)', class = 'b'),
  set_prior("lkj(2)", class = "cor")
)
```

build the model

```{r}
plan(multicore)
ab1 <- brm(formula = formula,
        data = data_acc, family = bernoulli(link = "logit"),
        prior = priors,
        iter = 4000, warmup = 1000, cores = 8, chains = 4,
        save_pars = save_pars(all=TRUE),
        seed = 123,
        file = "models/manifest/ab1")
summary(ab1)
```

pp_checks

```{r}
ppab1 <- pp_check(ab1, ndraws = 100)
ppab1
```

# 5. model diagnostics #

take a quick look at model diagnostics for the full rt and acc models

## rt model ##

### look at the chains ###

Here we visualise if the chains mixed reasonably well. We do this to see if there are any alarming patterns of non-mixing. You should see nicely overlapping caterpillar plots if all is well. This is only for the full model as it is the most complex, we would expect the less complex models to behave if this one behaves ok.

full rt model

```{r}
# this adds the chains from model b1 and creates a posterior samples dataframe called post
post_b1 <- as_draws_df(b1)
head(post_b1)

## here I only focus on the chains for the key variables of interest, but one can easily visualise all the variables if one wishes. Although you'll need a lot of separate figures...

post_b1 <- post_b1 %>%
  select(contains(c("b_", "sd_", ".chain"))) %>% # here I select fixed effects and sds. 
  mutate(chain = .chain)  

# now we plot them and save them as necessary
p_chains1 <- post_b1 %>%
  mcmc_trace(facet_args = list(ncol = 4)) +
  scale_x_continuous(breaks = c(0, 4000)) + # if you have 4000 post warm-up samples per chain
  theme_bw() +
  theme(legend.position = "bottom")
p_chains1
# save it
ggsave ("figures/manifest/b1_chains.jpeg",
        width = 8, height = 6)
```

chains look good

### other diagnostics ###

```{r}
b1_neff <- mcmc_plot(b1, type = "neff")
b1_neff

b1_rhat <- mcmc_plot(b1, type = "rhat")
b1_rhat

# this creates a combined plot
b1_diag <- b1_neff / b1_rhat 
b1_diag

ggsave("figures/manifest/b1_diag.jpeg",
       width = 8, height = 6)
```

## accuracy model ##

### look at the chains ###

```{r}
# this adds the chains from model ab1 and creates a posterior samples dataframe called post
post_ab1 <- as_draws_df(ab1)
head(post_ab1)

## here I only focus on the chains for the key variables of interest, but one can easily visualise all the variables if one wishes. Although you'll need a lot of separate figures...

post_ab1 <- post_ab1 %>%
  select(contains(c("b_", "sd_", ".chain"))) %>% # here I select fixed effects and sds. 
  mutate(chain = .chain)  

# now we plot them and save them as necessary
p_chains2 <- post_ab1 %>%
  mcmc_trace(facet_args = list(ncol = 3)) +
  scale_x_continuous(breaks = c(0, 3000)) + # if you have 4000 post warm-up samples per chain
  theme_bw() +
  theme(legend.position = "bottom")
p_chains2
# save it
ggsave ("figures/manifest/ab1_chains.jpeg",
        width = 8, height = 6)
```

chains look good

### other diagnostics ###

```{r}
ab1_neff <- mcmc_plot(ab1, type = "neff")
ab1_neff

ab1_rhat <- mcmc_plot(ab1, type = "rhat")
ab1_rhat

# this creates a combined plot
ab1_diag <- ab1_neff / ab1_rhat 
ab1_diag

ggsave("figures/manifest/ab1_diag.jpeg",
       width = 8, height = 6)
```


